{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd92c9bf-8490-48cf-9040-3e5f64a43307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tacotron2(\n",
       "  (embedding): Embedding(148, 512)\n",
       "  (encoder): Encoder(\n",
       "    (convolutions): ModuleList(\n",
       "      (0-2): 3 x Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (lstm): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (prenet): Prenet(\n",
       "      (layers): ModuleList(\n",
       "        (0): LinearNorm(\n",
       "          (linear_layer): Linear(in_features=80, out_features=256, bias=False)\n",
       "        )\n",
       "        (1): LinearNorm(\n",
       "          (linear_layer): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (attention_rnn): LSTMCell(768, 1024)\n",
       "    (attention_layer): Attention(\n",
       "      (query_layer): LinearNorm(\n",
       "        (linear_layer): Linear(in_features=1024, out_features=128, bias=False)\n",
       "      )\n",
       "      (memory_layer): LinearNorm(\n",
       "        (linear_layer): Linear(in_features=512, out_features=128, bias=False)\n",
       "      )\n",
       "      (v): LinearNorm(\n",
       "        (linear_layer): Linear(in_features=128, out_features=1, bias=False)\n",
       "      )\n",
       "      (location_layer): LocationLayer(\n",
       "        (location_conv): ConvNorm(\n",
       "          (conv): Conv1d(2, 32, kernel_size=(31,), stride=(1,), padding=(15,), bias=False)\n",
       "        )\n",
       "        (location_dense): LinearNorm(\n",
       "          (linear_layer): Linear(in_features=32, out_features=128, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder_rnn): LSTMCell(1536, 1024, bias=1)\n",
       "    (linear_projection): LinearNorm(\n",
       "      (linear_layer): Linear(in_features=1536, out_features=80, bias=True)\n",
       "    )\n",
       "    (gate_layer): LinearNorm(\n",
       "      (linear_layer): Linear(in_features=1536, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (postnet): Postnet(\n",
       "    (convolutions): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1-3): 3 x Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 80, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\n",
    "tacotron2 = tacotron2.to('cuda')\n",
    "tacotron2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48e8e67d-0250-4b69-9b79-e785ceec3cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WaveGlow(\n",
       "  (upsample): ConvTranspose1d(80, 80, kernel_size=(1024,), stride=(256,))\n",
       "  (WN): ModuleList(\n",
       "    (0-3): 4 x WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0-6): 7 x Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0-7): 8 x Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(4, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 8, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (4-7): 4 x WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0-6): 7 x Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0-7): 8 x Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 6, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (8-11): 4 x WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0-6): 7 x Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0-7): 8 x Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(2, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 4, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (convinv): ModuleList(\n",
       "    (0-3): 4 x Invertible1x1Conv(\n",
       "      (conv): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (4-7): 4 x Invertible1x1Conv(\n",
       "      (conv): Conv1d(6, 6, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (8-11): 4 x Invertible1x1Conv(\n",
       "      (conv): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp16')\n",
    "waveglow = waveglow.remove_weightnorm(waveglow)\n",
    "waveglow = waveglow.to('cuda')\n",
    "waveglow.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af410f4-aa00-4df6-a6d5-cd8b2b418d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello world, I missed you so much.\"\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9ac3d1d-2b60-449b-a970-9810fd776816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    }
   ],
   "source": [
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\n",
    "sequences, lengths = utils.prepare_input_sequence([text])\n",
    "lines = *map(str.strip,open(\"./transcription.txt\",'r',encoding='utf-8').readlines()),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e788331-d6cb-4542-956f-a3b6d66a9e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 a\n",
      "1 b\n",
      "2 c\n",
      "3 H\n",
      "4 I\n",
      "5 J\n",
      "Warning! Reached max decoder steps\n",
      "6 K\n",
      "7 L\n",
      "8 22222222 hello 22222222\n",
      "9 S D S D Pass zero - zero Fail - zero to zero - zero - zero Cancelled - fifty nine to three - two - ixty four Total - fifty nine to three - two -\n",
      "Warning! Reached max decoder steps\n",
      "10 S D S D Pass - zero - zero - zero - zero Fail - zero - zero - zero - zero Cancelled - four hundred nd sixteen - seventy six -\n",
      "Warning! Reached max decoder steps\n",
      "11 zero - one - one - two Cancelled - zero - zero - zero - zero Total - two hundred and eighty six - ineteen - seven -\n",
      "Warning! Reached max decoder steps\n",
      "12 forty one to five three hundred and eleven Fail - one - one to zero two Cancelled - zero - zero to ero zero Total -\n",
      "13 zero zero one , MS03 - zero twenty five , MS03 - zero thirty two , MS03 - zero thirty nine ,\n",
      "14 1b204928 zero zero zero zero zero zero zero zero zero zero zero zero zero zero one seven ole32\n",
      "15 zero zero zero zero zero zero zero zero two seven nine eight F three forty zero zero zero zero zero ix four two eight zero one eight\n",
      "16 c five eight zero three three nine a zero bf eight FALSE zero zero zero bba3add2 - c229 - 4cdb -\n",
      "17 Calendaring agent failed with error code 0x80070005 while saving appointment .\n",
      "18 Exit process - break ld - Load module - output ud - Unload module - ignore ser - System error - gnore ibp - Initial breakpoint -\n",
      "Warning! Reached max decoder steps\n",
      "19 Common DB connectors include the DB - nine , DB - fifteen , DB - nineteen , DB - twenty five , B - thirty seven , and DB - fifty connectors .\n",
      "Warning! Reached max decoder steps\n",
      "20 To deliver interfaces that are significantly better suited to create and process RFC eight twenty ne , RFC eight twenty two , RFC nine seventy seven , and MIME content .\n",
      "21 int1 , int2 , int3 , int4 , int5 , int6 , int7 , int8 , int9 ,\n",
      "22 seven _ ctl00 ctl04 ctl01 ctl00 ctl00\n",
      "23 Http0XX , Http1XX , Http2XX , Http3XX ,\n",
      "24 config file must contain A , B , C , D , E , F , and G .\n",
      "25 mondo - debug mondo - ship motif - debug motif - ship sts - debug sts - ship Comparing local iles to checkpoint files ...\n",
      "26 Rusbvts . dll Dsaccessbvts . dll Exchmembvt . dll Draino . dll Im trying to deploy a new topology  and I keep getting this error .\n",
      "Warning! Reached max decoder steps\n",
      "27 You can call me directly at four two five seven zero three seven three four four or my cell four two ive four four four seven four seven four or send me a meeting request with all the appropriate nformation .\n",
      "Warning! Reached max decoder steps\n",
      "28 Failed zero point zero zero percent < one zero zero one zero zero zero zero Internal . Exchange . ontentFilter . BVT ContentFilter . BVT_log . xml Error ! Filename not specified .\n",
      "Warning! Reached max decoder steps\n",
      "29 C colon backslash o one two f c p a r t y backslash d e v one two backslash oasys backslash egacy backslash web backslash HELP\n",
      "30 src backslash mapi backslash t n e f d e c dot c dot o l d backslash backslash m o z a r t f one ackslash e x five\n",
      "31 copy backslash backslash j o h n f a n four backslash scratch backslash M i c r o s o f t dot S h a r  P o i n t dot\n",
      "32 Take a look at h t t p colon slash slash w w w dot granite dot a b dot c a slash access slash email ot\n",
      "33 backslash bin backslash premium backslash forms backslash r e g i o n a l o p t i o n s dot a s p x ot c s Raj , DJ ,\n",
      "34 Anuraag backslash backslash r a d u r five backslash d e b u g dot one eight zero nine underscore  R two h dot s t s contains\n",
      "35 p l a t f o r m right bracket backslash left bracket f l a v o r right bracket backslash s e t u p dot e x\n",
      "36 backslash x eight six backslash Ship backslash zero backslash A d d r e s s B o o k dot C o n t a c  s A d d r e s\n",
      "37 Mine is here backslash backslash g a b e h a l l hyphen m o t h r a backslash S v r underscore O f  i c e s v r\n",
      "38 h t t p colon slash slash teams slash sites slash T A G slash default dot aspx As always , any eedback , comments ,\n",
      "39 two thousand and five h t t p colon slash slash news dot com dot com slash i slash n e slash f d lash two zero zero three slash f d\n",
      "Warning! Reached max decoder steps\n",
      "40 backslash i n t e r n a l dot e x c h a n g e dot m a n a g e m e n t dot s y s t e m m a n a g e\n",
      "41 I think Rich’s post highlights that we could have been more strategic about how the sum total of BOX three hundred and sixtys were distributed .\n",
      "42 64X64 , 8K , one hundred and eighty four ASSEMBLY , DIGITAL VIDEO DISK DRIVE , NTERNAL , 8X ,\n",
      "43 So we are back to Extended MAPI and C++ because . Extended MAPI does not have a dual nterface VB or VB .Net can read .\n",
      "44 Thanks , Borge Trongmo Hi gurus , Could you help us E2K ASP guys with the following issue ?\n",
      "45 Thanks J RGR Are you using the LDDM driver for this system or the in the build XDDM driver ?\n",
      "46 Btw , you might remember me from our discussion about OWA automation and OWA readiness ay a year ago .\n",
      "47 empidtool . exe creates HKEY_CURRENT_USER Software Microsoft Office Common MPersNum in the registry , queries AD , and the populate the registry with MS employment ID f available else an error code is logged .\n",
      "Warning! Reached max decoder steps\n",
      "48 Thursday, via a joint press release and Microsoft AI Blog, we will announce Microsoft’s ontinued partnership with Shell leveraging cloud, AI, and collaboration technology to drive ndustry innovation and transformation.\n",
      "Warning! Reached max decoder steps\n",
      "49 Actress Fan Bingbing attends the screening of ’Ash Is Purest White (Jiang Hu Er Nv)’ during the 71st annual Cannes Film Festival\n"
     ]
    }
   ],
   "source": [
    "for i,line in enumerate(lines):\n",
    "    text=line\n",
    "    print(i,text)\n",
    "    sequences, lengths = utils.prepare_input_sequence([text])\n",
    "    with torch.no_grad():\n",
    "        mel,mel_lengths, alignments  = tacotron2.infer(sequences, lengths)\n",
    "        plt.figure()\n",
    "        plt.title(\"alignment\")\n",
    "        plt.imshow(alignments.cpu().numpy()[0].T,aspect='auto',origin='lower',interpolation='none')    \n",
    "        plt.colorbar()        \n",
    "        plt.ylabel(\"encoder timestep\")\n",
    "        plt.xlabel(\"decoder timestep\")\n",
    "        plt.savefig(f\"./data/{i}_align.png\")                \n",
    "        plt.close('all') # closes the current figure\n",
    "        plt.figure()\n",
    "        plt.title(\"Mel-spectrogram\")\n",
    "        plt.imshow(mel.cpu().numpy()[0],aspect='auto',origin='lower',interpolation='none')        \n",
    "        plt.colorbar()    \n",
    "        #plt.show()\n",
    "        plt.savefig(f\"./data/{i}_spec.png\")             \n",
    "        plt.close('all') # closes the current figure\n",
    "        #print(mel_lengths.item())        \n",
    "        audio = waveglow.infer(mel)\n",
    "        audio_numpy = audio[0].data.cpu().numpy()\n",
    "        rate = 22050\n",
    "        write(f\"./data/{i}.wav\", rate, audio_numpy)\n",
    "\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb739ee2-a9b4-4d93-b79c-5cf7ad6147a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efebc3fa-61a9-4c0d-8230-d9b666570cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines = *map(str.strip,open(\"./untitled.txt\",'r',encoding='utf-8').readlines()),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0e353e-a17f-41d2-9284-0738e326c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ce326-3e12-4e55-a0e6-ef4aa4f2536a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
